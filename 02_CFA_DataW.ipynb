{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from matplotlib import rcParams\n",
    "#rcParams['figure.figsize'] = 30,9\n",
    "#!pip install seaborn\n",
    "import seaborn as sns\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_FMs = False     # Set to True if all CFA RF results shall be exported. \n",
    "multi_reg = False   # Multi regression output for tensorflow\n",
    "stress = False      # False if RF\n",
    "  \n",
    "###  True: Load is extracted at node A and B of beam element seperately. (MS_comp, stress, etc.)\n",
    "###  False: For FMs, where shear load is important, like joint frame to clip \n",
    "node_FM = True\n",
    "\n",
    "SEA_ele = True    # True means Location to GFEM element information is extracted from SE/SEA txt files.\n",
    "ele_sel = ['ELEMENTS_FRA', 'ELEMENTS_PAN1', 'ELEMENTS_PAN2'] # elements selected for output\n",
    "vali_modes =  ['auto','blind_panel','blind_LC']\n",
    "vali_mode = vali_modes[0]\n",
    "shells = ['US','LS','SS']\n",
    "shell = shells[2]\n",
    "\n",
    "name_in = \"A359_MSN216_S18LHS_SS\"\n",
    "folder_in = '01_Input/'\n",
    "folder_out = '02_Data/'\n",
    "\n",
    "folder_in = folder_in + name_in\n",
    "folder_out = folder_out + name_in\n",
    "\n",
    "#input_name = 'A359_MSN216_S18_'\n",
    "GFEM_name = 'GFEM_MSN216_' + shell\n",
    "geo_name = 'geo_US_MSN321.csv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the Failure Mode to be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RF_UL_FF_MS_comp', 'RF_UL_W_MS', 'RF_UL_FF_LS', 'RF_UL_W_BUCK', 'RF_UL_FF_LB']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'RF_UL_FF_MS_comp'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if node_FM is True:\n",
    "    FMs_node = ['RF_UL_FF_MS_comp', 'RF_UL_W_MS', 'RF_UL_FF_LS', 'RF_UL_W_BUCK', 'RF_UL_FF_LB']\n",
    "    FMs = FMs_node\n",
    "else:\n",
    "    FMs_joint = ['RF_UL_JOINT_FR_to_CLIP_CL', 'RF_UL_JOINT_FR_to_CLIP_FR',\n",
    "           'RF_UL_JOINT_SK_to_CLIP_CL_R', 'RF_UL_JOINT_SK_to_CLIP_SK_R']\n",
    "    FMs = FMs_node\n",
    "if all_FMs is True:\n",
    "    FMs = FMs_node + FMs_joint\n",
    "if stress is True:\n",
    "    FMs = ['sig_FF_UL', 'sig_OF_UL']\n",
    "print(FMs)\n",
    "considered_FM = FMs[0]\n",
    "considered_FM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ISAMI Results Data Frame\n",
    "\n",
    "-> created by '01_read_CFA' script\n",
    "\n",
    "Set to True if the frame structure assembly should be considered upside down. In this case, the load extraction is done on the upper side of the frame, at the level of the upper stringers.\n",
    "Set to False if the frame structure assembly is performed normally. In this case, the load extraction is done on the lower side of the frame, at the level of the lower stringers. See Figure 64.\n",
    "\n",
    "Set to NodeA : the load extraction is done on the frame SEA, NodeB : the load extraction is done on the upper side of the frame (opposite node), or NodeA_and_B : double extraction at both node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7888, 41)\n",
      "Number of unique LCs: 464\n",
      "Number of unique locations: 17\n",
      "Number of unique SEA: 17\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Load_Case_ID', 'AnalysisID', 'N_Fr_UL', 'M_Fr_UL', 'T_UL',\n",
       "       'f_x_Skin_L_UL', 'f_z_Skin_L_UL', 'f_xz_Skin_L_UL', 'f_x_Skin_R_UL',\n",
       "       'f_z_Skin_R_UL', 'f_xz_Skin_R_UL', 'Delta_p_UL', 'T_GFEM',\n",
       "       'Delta_Fx_UL', 'A_Fr', 'I_Fr', 'EA_Fr', 'yCG_Fr', 'b_eff_111_UL',\n",
       "       'b_eff_121_UL', 'path', 'RF_UL_FF_MS_comp', 'RF_UL_W_MS', 'RF_UL_FF_LS',\n",
       "       'RF_UL_JOINT_FR_to_CLIP_CL', 'RF_UL_JOINT_FR_to_CLIP_FR',\n",
       "       'RF_UL_W_BUCK', 'RF_UL_FF_LB', 'RF_UL_JOINT_SK_to_CLIP_CL_R',\n",
       "       'RF_UL_JOINT_SK_to_CLIP_SK_R', 'sig_FF_UL', 'sig_OF_UL', 'Node',\n",
       "       'Location_C', 'Location_P', 'SEA', 'GFEM_Label', 'Location_C2',\n",
       "       'Location_P2', 'Location_side', 'Location'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = 'df_' + name_in  + '_cfa.pkl'\n",
    "df_isami = pd.read_pickle(folder_out +'/'+input_file)\n",
    "#df_isami['LC_number'] = df_isami['LC_number'].astype(int).astype(str)\n",
    "# Un comment the following line for 'centered' Failure Modes, like Clip to skin joint. \n",
    "#Otherwise you will have 2 entries with alomst the same information,resulting in overfitting.\n",
    "#df_isami = df_isami.loc[df_isami['Node'] == 'F']\n",
    "print(df_isami.shape)\n",
    "print('Number of unique LCs: '+str(len(df_isami['GFEM_Label'].unique())))\n",
    "print('Number of unique locations: '+str(len(df_isami['Location'].unique())))\n",
    "print('Number of unique SEA: '+str(len(df_isami['SEA'].unique())))\n",
    "df_isami.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "(7888, 5)\n",
      "After cleaning:\n",
      "(2154, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GFEM_Label</th>\n",
       "      <th>RF_UL_FF_MS_comp</th>\n",
       "      <th>Location</th>\n",
       "      <th>SEA</th>\n",
       "      <th>Node</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XFB641</td>\n",
       "      <td>1795.60000</td>\n",
       "      <td>86_28_LHS</td>\n",
       "      <td>FRA-FR086-ST028-029</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XFB641N</td>\n",
       "      <td>8.33629</td>\n",
       "      <td>86_28_LHS</td>\n",
       "      <td>FRA-FR086-ST028-029</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XFB642N</td>\n",
       "      <td>12.81460</td>\n",
       "      <td>86_28_LHS</td>\n",
       "      <td>FRA-FR086-ST028-029</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GKN641</td>\n",
       "      <td>31.28570</td>\n",
       "      <td>86_28_LHS</td>\n",
       "      <td>FRA-FR086-ST028-029</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>GKN643</td>\n",
       "      <td>84.98980</td>\n",
       "      <td>86_28_LHS</td>\n",
       "      <td>FRA-FR086-ST028-029</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GFEM_Label  RF_UL_FF_MS_comp   Location                  SEA Node\n",
       "6      XFB641        1795.60000  86_28_LHS  FRA-FR086-ST028-029    A\n",
       "8     XFB641N           8.33629  86_28_LHS  FRA-FR086-ST028-029    A\n",
       "11    XFB642N          12.81460  86_28_LHS  FRA-FR086-ST028-029    A\n",
       "12     GKN641          31.28570  86_28_LHS  FRA-FR086-ST028-029    A\n",
       "20     GKN643          84.98980  86_28_LHS  FRA-FR086-ST028-029    A"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if multi_reg is False:\n",
    "    df_rf = df_isami[['GFEM_Label', considered_FM, 'Location', 'SEA', 'Node']]\n",
    "    print('Before cleaning:')\n",
    "    print(df_rf.shape)\n",
    "    df_rf = df_rf.loc[df_rf[considered_FM] != -9999.99].dropna()\n",
    "else:\n",
    "    df_rf = df_isami[['GFEM_Label', 'Location', 'SEA', 'Node']+FMs]\n",
    "    df_rf = df_rf.loc[df_rf[considered_FM] != -9999.99].dropna()\n",
    "\n",
    "print('After cleaning:')\n",
    "print(df_rf.shape)\n",
    "df_rf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LCDEF Data Frame\n",
    "Note: This is a work around. In future you should read this information directly from the LCDEF file.\n",
    "This is required for new op2/new load cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(464, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GFEM_Label</th>\n",
       "      <th>Event</th>\n",
       "      <th>LC_type</th>\n",
       "      <th>Thermal</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>LC_number</th>\n",
       "      <th>Thermal_code</th>\n",
       "      <th>Pressure_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZCT</td>\n",
       "      <td>Internal Pressure</td>\n",
       "      <td>DP</td>\n",
       "      <td>No-Thermal</td>\n",
       "      <td>Pressurized</td>\n",
       "      <td>501</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DT1.15</td>\n",
       "      <td>Internal Pressure</td>\n",
       "      <td>DP</td>\n",
       "      <td>No-Thermal</td>\n",
       "      <td>Pressurized</td>\n",
       "      <td>502</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FATIGUE</td>\n",
       "      <td>Fatigue</td>\n",
       "      <td>FAT</td>\n",
       "      <td>FAT</td>\n",
       "      <td>Pressurized</td>\n",
       "      <td>503</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FATGL1</td>\n",
       "      <td>Fatigue</td>\n",
       "      <td>FAT</td>\n",
       "      <td>FAT</td>\n",
       "      <td>Pressurized</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FATGL2</td>\n",
       "      <td>Fatigue</td>\n",
       "      <td>FAT</td>\n",
       "      <td>FAT</td>\n",
       "      <td>Pressurized</td>\n",
       "      <td>505</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  GFEM_Label              Event LC_type     Thermal     Pressure LC_number  \\\n",
       "0        ZCT  Internal Pressure      DP  No-Thermal  Pressurized       501   \n",
       "1     DT1.15  Internal Pressure      DP  No-Thermal  Pressurized       502   \n",
       "2    FATIGUE            Fatigue     FAT         FAT  Pressurized       503   \n",
       "3     FATGL1            Fatigue     FAT         FAT  Pressurized       504   \n",
       "4     FATGL2            Fatigue     FAT         FAT  Pressurized       505   \n",
       "\n",
       "   Thermal_code  Pressure_code  \n",
       "0             1              1  \n",
       "1             1              1  \n",
       "2             0              1  \n",
       "3             0              1  \n",
       "4             0              1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lcdef = pd.read_csv('04_LCDEF/LCDEF_event.csv')\n",
    "df_lcdef = df_lcdef[['GFEM_Label','Event', 'LC_type', 'Thermal', 'Pressure', 'LC_number']].dropna()\n",
    "lb_make = LabelEncoder()\n",
    "df_lcdef['Thermal_code'] = lb_make.fit_transform(df_lcdef['Thermal'])\n",
    "df_lcdef['Pressure_code'] = lb_make.fit_transform(df_lcdef['Pressure'])\n",
    "df_lcdef['LC_number'] = df_lcdef['LC_number'].astype(int).astype(str)\n",
    "#df_lcdef = df_lcdef[['LC_number', 'Thermal_code', 'Pressure_code', 'LC_type']]\n",
    "print(df_lcdef.shape)\n",
    "df_lcdef.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elements Data Frame (SEA + SE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SEA_ele is False:\n",
    "    input_file = name_in + '_Ele.csv'\n",
    "    df_isami_elements1 = pd.read_csv(folder_out+ '/QVLV/'+ input_file, index_col=0)\n",
    "    df_isami_elements = df_isami_elements1[['Location','FrameEl', 'SkinEl_LHS', 'SkinEl_RHS']].copy()\n",
    "    df_isami_elements[['FrameEl', 'SkinEl_LHS', 'SkinEl_RHS']] = df_isami_elements[['FrameEl', 'SkinEl_LHS', 'SkinEl_RHS']].astype(int).astype(str)\n",
    "    df_isami_elements.rename(columns={'FrameEl': 'ELEMENTS_FRA_1','SkinEl_LHS':'ELEMENTS_PAN1_1', 'SkinEl_RHS':'ELEMENTS_PAN2_1' }, inplace=True)\n",
    "    print(df_isami_elements.shape)\n",
    "    df_isami_elements.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_dir = folder_in + '/SEA_SE_FE/02_SEA_SE_FE_Mapping_Files/01_FF'\n",
    "subject_dirs = [x[0] for x in sorted(os.walk(parent_dir))]\n",
    "i = 0\n",
    "j = 0\n",
    "filelist = []\n",
    "for dir in subject_dirs:\n",
    "    csv_files = [os.path.join(dir, txt) for txt in os.listdir(dir) if os.path.isfile(os.path.join(dir, txt)) \n",
    "                 and txt.endswith('.txt') and ('out' not in txt)\n",
    "                ]\n",
    "    csv_files = sorted(csv_files)\n",
    "    for file in csv_files:\n",
    "        with open(file, \"rt\") as fin:\n",
    "            file_out = file[:-4]+'out.txt'\n",
    "            with open(file_out, \"wt\") as fout:\n",
    "                for line in fin:\n",
    "                    #line = line.replace('#SE', 'SE')\n",
    "                    line = line.replace('$', '#')\n",
    "                    fout.write(line)\n",
    "        f_name = file.split('/')\n",
    "        if any(x in f_name[-1] for x in ['FE2SE','SE2FE']):\n",
    "            df_FE2SE = pd.read_csv(file_out,sep=\":\",header=None, skip_blank_lines=True, comment=\"#\")\n",
    "            df_FE2SE['FILE'] = f_name[-1]\n",
    "            if i == 0:\n",
    "                df1 = df_FE2SE\n",
    "            else:\n",
    "                df1 = df1.append(df_FE2SE)\n",
    "            i = i + 1\n",
    "        elif any(x in f_name[-1] for x in ['SEA2SE','SE2SEA']):\n",
    "            df_SEA2SE = pd.read_csv(file_out,sep=\":\",header=None, skip_blank_lines=True, comment=\"#\")\n",
    "            df_SEA2SE['FILE'] = f_name[-1]\n",
    "            if j == 0:\n",
    "                df2 = df_SEA2SE\n",
    "            else:\n",
    "                df2 = df2.append(df_SEA2SE)\n",
    "            j = j + 1\n",
    "                \n",
    "SEA_list = ['PAN1','PAN2','FRA','STR1', 'STR2', 'STR3', 'STR4']\n",
    "df1[['TYPE','SE']] = df1[0].str.split(\" \",1, expand = True).astype(str)\n",
    "df2[['TYPE','SEA']] = df2[0].str.split(\" \",1, expand = True).astype(str)\n",
    "df1['SE'] = df1['SE'].str.replace(' ','')\n",
    "df2['SEA'] = df2['SEA'].str.replace(' ','')\n",
    "df1[2] = df1[1].str.replace(' ','').str.split(\",\", expand = False)\n",
    "df2[SEA_list]  = df2[1].str.replace(' ','').str.split(\",\", expand = True).astype(str)\n",
    "df1.rename(columns={2: 'ELEMENTS'}, inplace=True)\n",
    "df2 = df2[(df2.TYPE == 'AirbusSEA_Frame')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(any(df1['SE'].duplicated())) \n",
    "ids = df1['SE']\n",
    "df1[ids.isin(ids[ids.duplicated()])]\n",
    "#only keep the first(~)/last entry:\n",
    "df1 = df1[~df1['SE'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(any(df2['SEA'].duplicated())) \n",
    "#df2_d = df2[df2['SEA'].duplicated()]\n",
    "ids = df2['SEA']\n",
    "df2[ids.isin(ids[ids.duplicated()])]\n",
    "#only keep the first(~)/last entry:\n",
    "df2 = df2[~df2['SEA'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(657, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TYPE</th>\n",
       "      <th>SEA</th>\n",
       "      <th>PAN1</th>\n",
       "      <th>PAN2</th>\n",
       "      <th>FRA</th>\n",
       "      <th>STR1</th>\n",
       "      <th>STR2</th>\n",
       "      <th>STR3</th>\n",
       "      <th>STR4</th>\n",
       "      <th>ELEMENTS_PAN1</th>\n",
       "      <th>ELEMENTS_PAN2</th>\n",
       "      <th>ELEMENTS_FRA</th>\n",
       "      <th>ELEMENTS_STR1</th>\n",
       "      <th>ELEMENTS_STR2</th>\n",
       "      <th>ELEMENTS_STR3</th>\n",
       "      <th>ELEMENTS_STR4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AirbusSEA_Frame</td>\n",
       "      <td>FRA-FR072-ST006-007</td>\n",
       "      <td>Pan-FR071-072-ST006-007</td>\n",
       "      <td>Pan-FR072-073-ST006-007</td>\n",
       "      <td>Fra-FR072-ST006-007</td>\n",
       "      <td>Str-FR071-072-ST007</td>\n",
       "      <td>Str-FR071-072-ST006</td>\n",
       "      <td>Str-FR072-073-ST007</td>\n",
       "      <td>Str-FR072-073-ST006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7800710]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AirbusSEA_Frame</td>\n",
       "      <td>FRA-FR073-ST006-007</td>\n",
       "      <td>Pan-FR072-073-ST006-007</td>\n",
       "      <td>Pan-FR073-074-ST006-007</td>\n",
       "      <td>Fra-FR073-ST006-007</td>\n",
       "      <td>Str-FR072-073-ST007</td>\n",
       "      <td>Str-FR072-073-ST006</td>\n",
       "      <td>Str-FR073-074-ST007</td>\n",
       "      <td>Str-FR073-074-ST006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[7900710]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AirbusSEA_Frame</td>\n",
       "      <td>FRA-FR074-ST006-007</td>\n",
       "      <td>Pan-FR073-074-ST006-007</td>\n",
       "      <td>Pan-FR074-075-ST006-007</td>\n",
       "      <td>Fra-FR074-ST006-007</td>\n",
       "      <td>Str-FR073-074-ST007</td>\n",
       "      <td>Str-FR073-074-ST006</td>\n",
       "      <td>Str-FR074-075-ST007</td>\n",
       "      <td>Str-FR074-075-ST006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[8000710]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AirbusSEA_Frame</td>\n",
       "      <td>FRA-FR075-ST006-007</td>\n",
       "      <td>Pan-FR074-075-ST006-007</td>\n",
       "      <td>Pan-FR075-076-ST006-007</td>\n",
       "      <td>Fra-FR075-ST006-007</td>\n",
       "      <td>Str-FR074-075-ST007</td>\n",
       "      <td>Str-FR074-075-ST006</td>\n",
       "      <td>Str-FR075-076-ST007</td>\n",
       "      <td>Str-FR075-076-ST006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[8100710]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AirbusSEA_Frame</td>\n",
       "      <td>FRA-FR076-ST006-007</td>\n",
       "      <td>Pan-FR075-076-ST006-007</td>\n",
       "      <td>Pan-FR076-077-ST006-007</td>\n",
       "      <td>Fra-FR076-ST006-007</td>\n",
       "      <td>Str-FR075-076-ST007</td>\n",
       "      <td>Str-FR075-076-ST006</td>\n",
       "      <td>Str-FR076-077-ST007</td>\n",
       "      <td>Str-FR076-077-ST006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[8200710]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TYPE                  SEA                     PAN1  \\\n",
       "0  AirbusSEA_Frame  FRA-FR072-ST006-007  Pan-FR071-072-ST006-007   \n",
       "1  AirbusSEA_Frame  FRA-FR073-ST006-007  Pan-FR072-073-ST006-007   \n",
       "2  AirbusSEA_Frame  FRA-FR074-ST006-007  Pan-FR073-074-ST006-007   \n",
       "3  AirbusSEA_Frame  FRA-FR075-ST006-007  Pan-FR074-075-ST006-007   \n",
       "4  AirbusSEA_Frame  FRA-FR076-ST006-007  Pan-FR075-076-ST006-007   \n",
       "\n",
       "                      PAN2                  FRA                 STR1  \\\n",
       "0  Pan-FR072-073-ST006-007  Fra-FR072-ST006-007  Str-FR071-072-ST007   \n",
       "1  Pan-FR073-074-ST006-007  Fra-FR073-ST006-007  Str-FR072-073-ST007   \n",
       "2  Pan-FR074-075-ST006-007  Fra-FR074-ST006-007  Str-FR073-074-ST007   \n",
       "3  Pan-FR075-076-ST006-007  Fra-FR075-ST006-007  Str-FR074-075-ST007   \n",
       "4  Pan-FR076-077-ST006-007  Fra-FR076-ST006-007  Str-FR075-076-ST007   \n",
       "\n",
       "                  STR2                 STR3                 STR4  \\\n",
       "0  Str-FR071-072-ST006  Str-FR072-073-ST007  Str-FR072-073-ST006   \n",
       "1  Str-FR072-073-ST006  Str-FR073-074-ST007  Str-FR073-074-ST006   \n",
       "2  Str-FR073-074-ST006  Str-FR074-075-ST007  Str-FR074-075-ST006   \n",
       "3  Str-FR074-075-ST006  Str-FR075-076-ST007  Str-FR075-076-ST006   \n",
       "4  Str-FR075-076-ST006  Str-FR076-077-ST007  Str-FR076-077-ST006   \n",
       "\n",
       "  ELEMENTS_PAN1 ELEMENTS_PAN2 ELEMENTS_FRA ELEMENTS_STR1 ELEMENTS_STR2  \\\n",
       "0           NaN           NaN    [7800710]           NaN           NaN   \n",
       "1           NaN           NaN    [7900710]           NaN           NaN   \n",
       "2           NaN           NaN    [8000710]           NaN           NaN   \n",
       "3           NaN           NaN    [8100710]           NaN           NaN   \n",
       "4           NaN           NaN    [8200710]           NaN           NaN   \n",
       "\n",
       "  ELEMENTS_STR3 ELEMENTS_STR4  \n",
       "0           NaN           NaN  \n",
       "1           NaN           NaN  \n",
       "2           NaN           NaN  \n",
       "3           NaN           NaN  \n",
       "4           NaN           NaN  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "for item in SEA_list:\n",
    "    if i == 0:\n",
    "        df_ele = pd.merge(df2[['TYPE', 'SEA']+SEA_list], df1[['SE', 'ELEMENTS']],\n",
    "                  how='left', left_on=item, right_on='SE'\n",
    "                 ).drop(['SE'], axis=1)\n",
    "        \n",
    "    else:\n",
    "        df_ele = pd.merge(df_ele, df1[['SE', 'ELEMENTS']],\n",
    "          how='left', left_on=item, right_on='SE'\n",
    "         ).drop(['SE'], axis=1)\n",
    "    df_ele.rename(columns={'ELEMENTS': 'ELEMENTS_'+item}, inplace=True)\n",
    "    i = i +1\n",
    "print(df_ele.shape)\n",
    "df_ele.to_csv(folder_out+'/QVLV/'+ name_in + '_SEA2Ele.csv')\n",
    "df_ele.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ele_list = df_ele[['ELEMENTS_PAN1','ELEMENTS_PAN2']].values.ravel('K').tolist()\n",
    "#flattened_list = [y for x in ele_list for y in x]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometry Data Frame\n",
    "\n",
    "-> basis: ISAMI Results Data Frame -> to be merged with GFEM Data Frame in order to get geometry features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 8)\n",
      "17\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_Fr</th>\n",
       "      <th>I_Fr</th>\n",
       "      <th>EA_Fr</th>\n",
       "      <th>yCG_Fr</th>\n",
       "      <th>b_eff_111_UL</th>\n",
       "      <th>b_eff_121_UL</th>\n",
       "      <th>Location</th>\n",
       "      <th>SEA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>812.486</td>\n",
       "      <td>1199760.0</td>\n",
       "      <td>70540700.0</td>\n",
       "      <td>107.9150</td>\n",
       "      <td>317.5</td>\n",
       "      <td>317.5</td>\n",
       "      <td>86_28_LHS</td>\n",
       "      <td>FRA-FR086-ST028-029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>235.392</td>\n",
       "      <td>196841.0</td>\n",
       "      <td>19781600.0</td>\n",
       "      <td>97.4703</td>\n",
       "      <td>317.5</td>\n",
       "      <td>317.5</td>\n",
       "      <td>72_15_LHS</td>\n",
       "      <td>FRA-FR072-ST015-016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224.600</td>\n",
       "      <td>187589.0</td>\n",
       "      <td>18714200.0</td>\n",
       "      <td>95.8606</td>\n",
       "      <td>317.5</td>\n",
       "      <td>317.5</td>\n",
       "      <td>73_15_LHS</td>\n",
       "      <td>FRA-FR073-ST015-016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>218.417</td>\n",
       "      <td>181507.0</td>\n",
       "      <td>17539800.0</td>\n",
       "      <td>93.9115</td>\n",
       "      <td>317.5</td>\n",
       "      <td>317.5</td>\n",
       "      <td>74_15_LHS</td>\n",
       "      <td>FRA-FR074-ST015-016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168.766</td>\n",
       "      <td>137862.0</td>\n",
       "      <td>9719730.0</td>\n",
       "      <td>91.3548</td>\n",
       "      <td>317.5</td>\n",
       "      <td>317.5</td>\n",
       "      <td>75_15_LHS</td>\n",
       "      <td>FRA-FR075-ST015-016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      A_Fr       I_Fr       EA_Fr    yCG_Fr  b_eff_111_UL  b_eff_121_UL  \\\n",
       "0  812.486  1199760.0  70540700.0  107.9150         317.5         317.5   \n",
       "1  235.392   196841.0  19781600.0   97.4703         317.5         317.5   \n",
       "2  224.600   187589.0  18714200.0   95.8606         317.5         317.5   \n",
       "3  218.417   181507.0  17539800.0   93.9115         317.5         317.5   \n",
       "4  168.766   137862.0   9719730.0   91.3548         317.5         317.5   \n",
       "\n",
       "    Location                  SEA  \n",
       "0  86_28_LHS  FRA-FR086-ST028-029  \n",
       "1  72_15_LHS  FRA-FR072-ST015-016  \n",
       "2  73_15_LHS  FRA-FR073-ST015-016  \n",
       "3  74_15_LHS  FRA-FR074-ST015-016  \n",
       "4  75_15_LHS  FRA-FR075-ST015-016  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geom_par = ['A_Fr','I_Fr', 'EA_Fr', 'yCG_Fr', 'b_eff_111_UL', 'b_eff_121_UL']\n",
    "list1 = ['GFEM_Label','Location', 'SEA']\n",
    "df_geom = df_isami[geom_par + list1]\n",
    "df_geom = df_geom.loc[df_geom['GFEM_Label'] == 'DT1.15'].dropna().drop_duplicates().reset_index(drop=True).drop('GFEM_Label',axis=1)\n",
    "print(df_geom.shape)\n",
    "# df_geom.to_csv('df_geom.csv')\n",
    "a1 = df_geom['Location'].unique()\n",
    "print(len(a1))\n",
    "#pd.DataFrame(a1).to_clipboard()\n",
    "df_geom.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geometry from fishtail file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ft = pd.read_pickle(folder_out+'/' +'df_'+name_in + '_geo.pkl')\n",
    "# label encoding\n",
    "encodes = ['MATERIAL TYPE_frame', 'MATERIAL TYPE_clip', 'FAMILY_clip']\n",
    "for encode in encodes:\n",
    "    df_ft[encode + '_code'] = lb_make.fit_transform(df_ft[encode])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(618, 56)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AIRBUSSEA_FRAME</th>\n",
       "      <th>CLIPPROFILE</th>\n",
       "      <th>CLIPLENGTH (mm)</th>\n",
       "      <th>CLIPPOSITIONX (mm)</th>\n",
       "      <th>JOINT_FRA_CLIP</th>\n",
       "      <th>FRA_CLIP_HEADSIDE</th>\n",
       "      <th>JOINT_FRACLIP_SKIN</th>\n",
       "      <th>FRACLIP_SKIN_HEADSIDE</th>\n",
       "      <th>LOWERSTAB</th>\n",
       "      <th>LOWERSTABPOSITIONX (mm)</th>\n",
       "      <th>...</th>\n",
       "      <th>45.0_clip</th>\n",
       "      <th>90.0_clip</th>\n",
       "      <th>A_Fr</th>\n",
       "      <th>I_Fr</th>\n",
       "      <th>EA_Fr</th>\n",
       "      <th>yCG_Fr</th>\n",
       "      <th>b_eff_111_UL</th>\n",
       "      <th>b_eff_121_UL</th>\n",
       "      <th>Location</th>\n",
       "      <th>SEA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FRA-Fra-FR072-ST008-009</td>\n",
       "      <td>Clip_C72_P8</td>\n",
       "      <td>208.67</td>\n",
       "      <td>0</td>\n",
       "      <td>FA_C72P_8</td>\n",
       "      <td>Frame</td>\n",
       "      <td>FP_C72P_8</td>\n",
       "      <td>Skin</td>\n",
       "      <td>Dummy Stabilo</td>\n",
       "      <td>208.67</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FRA-Fra-FR072-ST009-010</td>\n",
       "      <td>Clip_C72_P9</td>\n",
       "      <td>220.00</td>\n",
       "      <td>0</td>\n",
       "      <td>FA_C72P_9</td>\n",
       "      <td>Frame</td>\n",
       "      <td>FP_C72P_9</td>\n",
       "      <td>Skin</td>\n",
       "      <td>Dummy Stabilo</td>\n",
       "      <td>220.00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FRA-Fra-FR072-ST010-011</td>\n",
       "      <td>Clip_C72_P10</td>\n",
       "      <td>208.67</td>\n",
       "      <td>0</td>\n",
       "      <td>FA_C72P_10</td>\n",
       "      <td>Frame</td>\n",
       "      <td>FP_C72P_10</td>\n",
       "      <td>Skin</td>\n",
       "      <td>Lower_Stabilo_C72P10</td>\n",
       "      <td>208.67</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FRA-Fra-FR072-ST011-012</td>\n",
       "      <td>Clip_C72_P11</td>\n",
       "      <td>208.67</td>\n",
       "      <td>0</td>\n",
       "      <td>FA_C72P_11</td>\n",
       "      <td>Frame</td>\n",
       "      <td>FP_C72P_11</td>\n",
       "      <td>Skin</td>\n",
       "      <td>Lower_Stabilo_C72P11</td>\n",
       "      <td>208.67</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FRA-Fra-FR072-ST012-013</td>\n",
       "      <td>Clip_C72_P12</td>\n",
       "      <td>208.67</td>\n",
       "      <td>0</td>\n",
       "      <td>FA_C72P_12</td>\n",
       "      <td>Frame</td>\n",
       "      <td>FP_C72P_12</td>\n",
       "      <td>Skin</td>\n",
       "      <td>Lower_Stabilo_C72P12</td>\n",
       "      <td>208.67</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AIRBUSSEA_FRAME   CLIPPROFILE  CLIPLENGTH (mm)  CLIPPOSITIONX (mm)  \\\n",
       "0  FRA-Fra-FR072-ST008-009   Clip_C72_P8           208.67                   0   \n",
       "1  FRA-Fra-FR072-ST009-010   Clip_C72_P9           220.00                   0   \n",
       "2  FRA-Fra-FR072-ST010-011  Clip_C72_P10           208.67                   0   \n",
       "3  FRA-Fra-FR072-ST011-012  Clip_C72_P11           208.67                   0   \n",
       "4  FRA-Fra-FR072-ST012-013  Clip_C72_P12           208.67                   0   \n",
       "\n",
       "  JOINT_FRA_CLIP FRA_CLIP_HEADSIDE JOINT_FRACLIP_SKIN FRACLIP_SKIN_HEADSIDE  \\\n",
       "0      FA_C72P_8             Frame          FP_C72P_8                  Skin   \n",
       "1      FA_C72P_9             Frame          FP_C72P_9                  Skin   \n",
       "2     FA_C72P_10             Frame         FP_C72P_10                  Skin   \n",
       "3     FA_C72P_11             Frame         FP_C72P_11                  Skin   \n",
       "4     FA_C72P_12             Frame         FP_C72P_12                  Skin   \n",
       "\n",
       "              LOWERSTAB  LOWERSTABPOSITIONX (mm) ...  45.0_clip  90.0_clip  \\\n",
       "0         Dummy Stabilo                   208.67 ...        2.0        0.0   \n",
       "1         Dummy Stabilo                   220.00 ...        2.0        0.0   \n",
       "2  Lower_Stabilo_C72P10                   208.67 ...        2.0        0.0   \n",
       "3  Lower_Stabilo_C72P11                   208.67 ...        2.0        0.0   \n",
       "4  Lower_Stabilo_C72P12                   208.67 ...        2.0        0.0   \n",
       "\n",
       "  A_Fr I_Fr  EA_Fr  yCG_Fr b_eff_111_UL  b_eff_121_UL  Location  SEA  \n",
       "0  NaN  NaN    NaN     NaN          NaN           NaN       NaN  NaN  \n",
       "1  NaN  NaN    NaN     NaN          NaN           NaN       NaN  NaN  \n",
       "2  NaN  NaN    NaN     NaN          NaN           NaN       NaN  NaN  \n",
       "3  NaN  NaN    NaN     NaN          NaN           NaN       NaN  NaN  \n",
       "4  NaN  NaN    NaN     NaN          NaN           NaN       NaN  NaN  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geoc = pd.merge(df_ft, df_geom, \n",
    "                        how='left', left_on=['SEA_MSN216'], right_on=['SEA']).drop('SEA_MSN216', axis=1)\n",
    "df_geoc = df_geoc.reset_index(drop=True)\n",
    "print(df_geoc.shape)\n",
    "df_geoc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLD: Geometry from fishtail file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'df_ft = pd.read_csv(folder_out+\\'/\\'+geo_name)\\nparams = df_ft[\\'param\\'].unique().tolist()\\npara = params[0]\\n\\n# This code works for A351 clip geo\\n#df_ft[\\'Location_C\\'] = df_ft[\\'Profile\\'].str.split(\\'_\\').str[-2].str.replace(\\'.\\',\\'0\\').str.replace(\\'C\\',\\'\\')\\ndf_ft.loc[df_ft[\\'Profile\\'].str.contains(r\\'Clp_\\'),\\'Location_C\\'] = df_ft[\\'Profile\\'].str.split(\\'_\\').str[-2].str.replace(\\'.\\',\\'0\\').str.replace(\\'C\\',\\'\\') \\ndf_ft.loc[df_ft[\\'Profile\\'].str.contains(r\\'IF_FC_LJ\\'),\\'Location_C\\'] = df_ft[\\'Profile\\'].str.split(\\'_\\').str[-3].str.replace(\\'.\\',\\'0\\').str.replace(\\'C\\',\\'\\')\\n#df_ft[\\'Location_P\\'] = df_ft[\\'Profile\\'].str.split(\\'_\\').str[-1].str.replace(r\\'Pr*\\',\\'\\')\\ndf_ft.loc[df_ft[\\'Profile\\'].str.contains(r\\'Clp_\\'),\\'Location_P\\'] = df_ft[\\'Profile\\'].str.split(\\'_\\').str[-1].str.replace(r\\'Pr*\\',\\'\\')\\ndf_ft.loc[df_ft[\\'Profile\\'].str.contains(r\\'IF_FC_LJ\\'),\\'Location_P\\'] = df_ft[\\'Profile\\'].str.split(\\'_\\').str[-2].str.replace(r\\'Pr*\\',\\'\\')\\n\\ndf_ft.loc[df_ft[\\'Profile\\'].str.contains(r\\'_P\\\\d\\'),\\'Location_side\\'] = \\'LHS\\'\\ndf_ft.loc[df_ft[\\'Profile\\'].str.contains(r\\'_Pr\\'),\\'Location_side\\'] = \\'RHS\\'\\ndf_ft.loc[df_ft[\\'Profile\\'].str.contains(r\\'_TL\\'),\\'Location_side\\'] = \\'LHS\\'\\ndf_ft[\\'Location\\'] = df_ft[\\'Location_C\\'] + \"_\" + df_ft[\\'Location_P\\'] + \"_\" + df_ft[\\'Location_side\\']\\ndfclp = df_ft[[\\'Profile\\',\\'Location_C\\',\\'Location\\',\\'MatType\\',\\'Family\\', \\'h\\', \\'tw\\'] ]\\ndfclp.isnull().sum()\\n\\ndf_ft.loc[df_ft[\\'P_pos\\'].str.contains(r\\'P\\\\d\\'),\\'Location_side\\'] = \\'LHS\\'\\ndf_ft.loc[df_ft[\\'P_pos\\'].str.contains(r\\'Pr\\'),\\'Location_side\\'] = \\'RHS\\'\\ndf_ft.loc[df_ft[\\'P_pos\\'].str.contains(r\\'TL\\'),\\'Location_side\\'] = \\'LHS\\'\\ndf_ft.loc[df_ft[\\'P_pos\\'].str.contains(r\\'rTL|TLr\\'),\\'Location_side\\'] = \\'RHS\\'\\ndf_ft[\\'Location_P\\'] = df_ft[\\'P_pos\\'].str.replace(r\\'Pr?|r\\',\\'\\')\\ndf_ft.loc[df_ft[\\'Location_P\\'].str.contains(r\\'TL\\'),\\'Location_P\\'] = \\'0\\'\\ndf_ft = df_ft.drop([\\'P_pos\\'], axis=1)\\ndf_ft2 = df_ft.melt(id_vars=[\\'Location_P\\',\\'Location_side\\', \\'param\\'])\\ndf_ft2[\\'Location\\'] = df_ft2[\\'variable\\'] + \"_\" + df_ft2[\\'Location_P\\'] + \"_\" + df_ft2[\\'Location_side\\']\\ndf_ft2 = df_ft2.pivot(index=\\'Location\\',columns=\\'param\\', values=\\'value\\')\\ndf_ft2.head()\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df_ft = pd.read_csv(folder_out+'/'+geo_name)\n",
    "params = df_ft['param'].unique().tolist()\n",
    "para = params[0]\n",
    "\n",
    "# This code works for A351 clip geo\n",
    "#df_ft['Location_C'] = df_ft['Profile'].str.split('_').str[-2].str.replace('.','0').str.replace('C','')\n",
    "df_ft.loc[df_ft['Profile'].str.contains(r'Clp_'),'Location_C'] = df_ft['Profile'].str.split('_').str[-2].str.replace('.','0').str.replace('C','') \n",
    "df_ft.loc[df_ft['Profile'].str.contains(r'IF_FC_LJ'),'Location_C'] = df_ft['Profile'].str.split('_').str[-3].str.replace('.','0').str.replace('C','')\n",
    "#df_ft['Location_P'] = df_ft['Profile'].str.split('_').str[-1].str.replace(r'Pr*','')\n",
    "df_ft.loc[df_ft['Profile'].str.contains(r'Clp_'),'Location_P'] = df_ft['Profile'].str.split('_').str[-1].str.replace(r'Pr*','')\n",
    "df_ft.loc[df_ft['Profile'].str.contains(r'IF_FC_LJ'),'Location_P'] = df_ft['Profile'].str.split('_').str[-2].str.replace(r'Pr*','')\n",
    "\n",
    "df_ft.loc[df_ft['Profile'].str.contains(r'_P\\d'),'Location_side'] = 'LHS'\n",
    "df_ft.loc[df_ft['Profile'].str.contains(r'_Pr'),'Location_side'] = 'RHS'\n",
    "df_ft.loc[df_ft['Profile'].str.contains(r'_TL'),'Location_side'] = 'LHS'\n",
    "df_ft['Location'] = df_ft['Location_C'] + \"_\" + df_ft['Location_P'] + \"_\" + df_ft['Location_side']\n",
    "dfclp = df_ft[['Profile','Location_C','Location','MatType','Family', 'h', 'tw'] ]\n",
    "dfclp.isnull().sum()\n",
    "\n",
    "df_ft.loc[df_ft['P_pos'].str.contains(r'P\\d'),'Location_side'] = 'LHS'\n",
    "df_ft.loc[df_ft['P_pos'].str.contains(r'Pr'),'Location_side'] = 'RHS'\n",
    "df_ft.loc[df_ft['P_pos'].str.contains(r'TL'),'Location_side'] = 'LHS'\n",
    "df_ft.loc[df_ft['P_pos'].str.contains(r'rTL|TLr'),'Location_side'] = 'RHS'\n",
    "df_ft['Location_P'] = df_ft['P_pos'].str.replace(r'Pr?|r','')\n",
    "df_ft.loc[df_ft['Location_P'].str.contains(r'TL'),'Location_P'] = '0'\n",
    "df_ft = df_ft.drop(['P_pos'], axis=1)\n",
    "df_ft2 = df_ft.melt(id_vars=['Location_P','Location_side', 'param'])\n",
    "df_ft2['Location'] = df_ft2['variable'] + \"_\" + df_ft2['Location_P'] + \"_\" + df_ft2['Location_side']\n",
    "df_ft2 = df_ft2.pivot(index='Location',columns='param', values='value')\n",
    "df_ft2.head()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GFEM Data Frame\n",
    "\n",
    "-> created by the 'read_GFEM' script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'02_Data/A359_MSN216_S18LHS_SS/df_GFEM_MSN216_SS_frames.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-271b9195a61f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'df_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGFEM_name\u001b[0m \u001b[0;34m+\u001b[0m  \u001b[0;34m'_frames.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_gfem_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_out\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_gfem_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Loadcase'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_gfem_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Loadcase'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_gfem_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ElementID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_gfem_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ElementID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_gfem_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_gfem_frames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bending_moment_a2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bending_moment_b2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shear2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'torque'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'02_Data/A359_MSN216_S18LHS_SS/df_GFEM_MSN216_SS_frames.csv' does not exist"
     ]
    }
   ],
   "source": [
    "input_file = 'df_' + GFEM_name +  '_frames.csv'\n",
    "df_gfem_frames = pd.read_csv(folder_out+'/'+input_file).drop(['Unnamed: 0'], axis=1)\n",
    "df_gfem_frames['Loadcase'] = df_gfem_frames['Loadcase'].astype(int).astype(str)\n",
    "df_gfem_frames['ElementID'] = df_gfem_frames['ElementID'].astype(int).astype(str)\n",
    "df_gfem_frames = df_gfem_frames.drop(['bending_moment_a2', 'bending_moment_b2', 'shear2', 'torque'], axis=1)\n",
    "df_gfem_frames.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'02_Data/A359_MSN216_S18LHS_SS/df_GFEM_MSN216_SS_skin.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-60a1f53ee59f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'df_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mGFEM_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_skin.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_gfem_skin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_out\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_gfem_skin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Loadcase'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_gfem_skin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Loadcase'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_gfem_skin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ElementID'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_gfem_skin\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ElementID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#df_gfem_skin.head()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'02_Data/A359_MSN216_S18LHS_SS/df_GFEM_MSN216_SS_skin.csv' does not exist"
     ]
    }
   ],
   "source": [
    "input_file = 'df_' + GFEM_name + '_skin.csv'\n",
    "df_gfem_skin = pd.read_csv(folder_out+'/'+input_file).drop(['Unnamed: 0'], axis=1)\n",
    "df_gfem_skin['Loadcase'] = df_gfem_skin['Loadcase'].astype(int).astype(str)\n",
    "df_gfem_skin['ElementID'] = df_gfem_skin['ElementID'].astype(int).astype(str)\n",
    "#df_gfem_skin.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Database Join\n",
    "\n",
    "Note:  Skin_LHS -> _x      |      Skin_RHS -> _y\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_rf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e6268c0f5585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mSEA_ele\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpos_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Node'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SEA'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpos_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Location'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Node'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m df_combined = pd.merge(df_rf[['GFEM_Label'] + pos_var + FMs], df_geoc[feat_loc_list],\n\u001b[0m\u001b[1;32m     14\u001b[0m                          how='left', left_on=['SEA'], right_on=['SEA'])\n\u001b[1;32m     15\u001b[0m \u001b[0;31m### Merge with Load Case info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_rf' is not defined"
     ]
    }
   ],
   "source": [
    "#features_geom = ['A_Fr', 'I_Fr', 'EA_Fr', 'yCG_Fr', 'ba','hclp','nofastfr','nofastsk','tclp','tfr','tskin']\n",
    "features_geom = ['CLIPLENGTH (mm)','OFFSETY0 (mm)', 'OFFSETZ0 (mm)',  \n",
    "                 'T (mm)_frame', 'TW (mm)_frame','MATERIAL TYPE_frame_code', \n",
    "                 'BA (mm)_frame', 'BF (mm)_frame', 'H (mm)_frame',\n",
    "                 'T (mm)_clip', 'TW (mm)_clip','MATERIAL TYPE_clip_code',\n",
    "                 'FAMILY_clip_code', 'BA (mm)_clip', 'H (mm)_clip',\n",
    "                 '-45.0_frame', '0.0_frame', '45.0_frame', '90.0_frame', '-45.0_clip',\n",
    "                 '0.0_clip', '45.0_clip', '90.0_clip'\n",
    "                ]\n",
    "feat_loc_list =  ['SEA'] + features_geom\n",
    "if SEA_ele is True: pos_var = ['Location', 'Node', 'SEA']\n",
    "else: pos_var = ['Location', 'Node']\n",
    "df_combined = pd.merge(df_rf[['GFEM_Label'] + pos_var + FMs], df_geoc[feat_loc_list],\n",
    "                         how='left', left_on=['SEA'], right_on=['SEA'])\n",
    "### Merge with Load Case info\n",
    "df_combined = pd.merge(df_combined, df_lcdef[['LC_number', 'Thermal_code', 'Pressure_code', 'LC_type', 'GFEM_Label']], \n",
    "                        how='left', on=['GFEM_Label'])\n",
    "### Merge with FEM element info\n",
    "if SEA_ele is True:\n",
    "    df_combined = pd.merge(df_combined, df_ele[['SEA'] + ele_sel], how='left', on=['SEA'])\n",
    "    df_combined[['ELEMENTS_FRA_1','ELEMENTS_FRA_2']] = pd.DataFrame(df_combined['ELEMENTS_FRA'].values.tolist(), index= df_combined.index)\n",
    "    df_combined[['ELEMENTS_PAN1_1', 'ELEMENTS_PAN1_2']] = pd.DataFrame(df_combined['ELEMENTS_PAN1'].values.tolist(), index= df_combined.index)\n",
    "    df_combined[['ELEMENTS_PAN2_1', 'ELEMENTS_PAN2_2']] = pd.DataFrame(df_combined['ELEMENTS_PAN2'].values.tolist(), index= df_combined.index)\n",
    "else:\n",
    "    df_combined = pd.merge(df_combined, df_isami_elements, how='left', left_on=['Location'],\n",
    "                      right_on=['Location'])\n",
    "df_pp = df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START Load Extraction\n",
    "#df_combined = pd.merge(df_combined, df_gfem_frames, how='left', left_on=['LC_number', 'FrameEl'],\n",
    "#                      right_on=['Loadcase', 'ElementID'])\n",
    "df_combined1 = pd.merge(df_combined.loc[df_combined['Node'] == 'F'], \n",
    "                        df_gfem_frames.loc[:, df_gfem_frames.columns != 'bending_moment_b1'], how='left', left_on=['LC_number', 'ELEMENTS_FRA_1'],\n",
    "                      right_on=['Loadcase', 'ElementID'])\n",
    "df_combined1.rename(columns={'bending_moment_a1': 'bending_moment'}, inplace=True)\n",
    "df_combined2 = pd.merge(df_combined.loc[df_combined['Node'] == 'T'], \n",
    "                        df_gfem_frames.loc[:, df_gfem_frames.columns != 'bending_moment_a1'], how='left', left_on=['LC_number', 'ELEMENTS_FRA_1'],\n",
    "                      right_on=['Loadcase', 'ElementID'])\n",
    "df_combined2.rename(columns={'bending_moment_b1': 'bending_moment'}, inplace=True)\n",
    "df_combined = pd.concat([df_combined1, df_combined2])\n",
    "### END Load Extraction\n",
    "\n",
    "print(df_combined.shape)\n",
    "#df4 = df_combined\n",
    "###   ATTENTION!!!! drop all na!\n",
    "#df_combined = df_combined.dropna()\n",
    "print(df_combined.shape)\n",
    "df_combined = pd.merge(df_combined, df_gfem_skin, how='left', left_on=['LC_number', 'ELEMENTS_PAN1_1'],\n",
    "                      right_on=['Loadcase', 'ElementID'])\n",
    "df_combined = pd.merge(df_combined, df_gfem_skin, how='left', left_on=['LC_number', 'ELEMENTS_PAN2_1'],\n",
    "                      right_on=['Loadcase', 'ElementID'])\n",
    "print(df_combined.shape)\n",
    "print(df_combined.columns)\n",
    "#df4[df4.isnull().any(axis=1)]\n",
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFmax = 20\n",
    "features_loads = ['bending_moment', #'bending_moment_b1', \n",
    "                  'shear1', 'axial',\n",
    "                  'mx_x', 'my_x', 'mxy_x', 'mx_y', 'my_y', 'mxy_y']\n",
    "features_lcdef = ['Pressure_code', 'Thermal_code']\n",
    "col_pp = ['LC_number','GFEM_Label','LC_type'] + pos_var\n",
    "features = features_geom + features_loads + features_lcdef\n",
    "if multi_reg is False:\n",
    "    columns_all = [considered_FM] + features\n",
    "else:\n",
    "    columns_all = FMs + features\n",
    "col_pp2 = columns_all + col_pp\n",
    "df_all1 = df_combined[col_pp2].dropna()\n",
    "\n",
    "if stress is False:\n",
    "    if multi_reg is False:\n",
    "        df_all1 = df_all1.loc[df_combined[considered_FM] != -9999.99]\n",
    "        df_all = df_all1.loc[df_combined[considered_FM] < RFmax]\n",
    "    else:\n",
    "        df_all1[FMs] = df_all1[FMs].replace(-9999.99, RFmax)\n",
    "        df_all1[FMs] = df_all1[FMs].apply(lambda x: np.where(x < RFmax,x,RFmax))\n",
    "        df_all = df_all1\n",
    "else:\n",
    "    df_all = df_all1\n",
    "df_features = df_all[features]\n",
    "df_feat_pp = df_all[features + col_pp]\n",
    "if multi_reg is False:\n",
    "    df_result = df_all[considered_FM]\n",
    "else:\n",
    "    df_result = df_all[FMs]\n",
    "print(df_all.shape)\n",
    "print(df_features.shape)\n",
    "print(df_result.shape)\n",
    "\n",
    "df_all.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collect the LC's, which results in the lowest 5% of RF for each location.\n",
    "if vali_mode == \"blind_LC\":\n",
    "    df_all_grp = df_all[[considered_FM,'Location','LC_number','LC_name']].groupby(['Location'])\n",
    "    df_all_stat = df_all_grp.describe(percentiles=[.05, .5, .95])\n",
    "    df_all_stat.columns = df_all_stat.columns.droplevel()\n",
    "    df_blindLC = pd.DataFrame()\n",
    "    for key, group in df_all_grp:\n",
    "        df = df_all_grp.get_group(key)\n",
    "        RF_blind = df_all_stat.loc[key,'5%']\n",
    "        if RF_blind > 1.1: RF_blind = 1.1\n",
    "        df = df.loc[df[considered_FM] < RF_blind]\n",
    "        df_blindLC = df_blindLC.append(df)\n",
    "        #r2 = r2_score(df['RF_calculated'], df['RF_predicted'])\n",
    "        #df_r2.loc[key] = r2\n",
    "    print(df_blindLC.shape)\n",
    "    blind = df_blindLC['LC_name'].unique().tolist()\n",
    "    print(len(blind))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vali_mode == \"auto\":\n",
    "    X_train, X_test_pp, y_train, y_test = train_test_split(df_feat_pp, df_result, test_size = 0.25, random_state = 6)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_features, df_result, test_size = 0.25, random_state = 6)\n",
    "    \n",
    "elif vali_mode == \"blind_LC\":\n",
    "    #blind =['XLF655P', 'GVB653']\n",
    "    ######################################\n",
    "    X_train = df_features.loc[~df_all['LC_name'].isin(blind),:]\n",
    "    X_test = df_features.loc[df_all['LC_name'].isin(blind),:]\n",
    "    X_test_pp = df_feat_pp.loc[df_all['LC_name'].isin(blind),:]\n",
    "    y_train = df_result.loc[~df_all['LC_name'].isin(blind),]\n",
    "    y_test = df_result.loc[df_all['LC_name'].isin(blind),]\n",
    "\n",
    "else:\n",
    "    blind =['88_2_LHS', '74_6_RHS']\n",
    "    ######################################\n",
    "    X_train = df_features.loc[~df_all['Location'].isin(blind),:]\n",
    "    X_test = df_features.loc[df_all['Location'].isin(blind),:]\n",
    "    X_test_pp = df_feat_pp.loc[df_all['Location'].isin(blind),:]\n",
    "    y_train = df_result.loc[~df_all['Location'].isin(blind),]\n",
    "    y_test = df_result.loc[df_all['Location'].isin(blind),]\n",
    "\n",
    "input_name = name_in + '_'\n",
    "folder_pkl = folder_out + '/clean'\n",
    "X_train.to_pickle(folder_pkl + '/' + input_name + \"X_train.pkl\")\n",
    "X_test.to_pickle(folder_pkl + '/' + input_name + \"X_test.pkl\")\n",
    "X_test_pp.to_pickle(folder_pkl + '/' + input_name + \"X_test_pp.pkl\")\n",
    "y_train.to_pickle(folder_pkl + '/' + input_name + \"y_train.pkl\")\n",
    "y_test.to_pickle(folder_pkl + '/' + input_name + \"y_test.pkl\")\n",
    "print(features)\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(X_test_pp.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Hyperview results file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = folder_out + '/' + input_name + \"hvout.hwascii\"\n",
    "header = ['ALTAIR ASCII FILE ',\n",
    "        '$TITLE = CFA Analysis Min RF MSN216',\n",
    "        '$SUBCASE = 1 ' + considered_FM  ,\n",
    "        '$BINDING = ELEMENT ',\n",
    "        '$COLUMN_INFO=   ENTITY_ID ',\n",
    "        '$RESULT_TYPE =  RF, SLoadcase'\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_SEA2EL = df_pp[['Location', 'SEA', 'ELEMENTS_FRA_1', 'ELEMENTS_FRA_2']].drop_duplicates(['SEA'])\n",
    "### used for the post processing of the ML output:\n",
    "df_SEA2EL.to_pickle(folder_out + '/' + input_name + \"SEA2EL.pkl\")\n",
    "\n",
    "infos = ['GFEM_Label', 'Location', 'Node', 'SEA', 'LC_number', 'LC_type',\n",
    "       'ELEMENTS_FRA_1', 'ELEMENTS_FRA_2']\n",
    "df_pp = df_pp[infos + FMs]\n",
    "df_pp[FMs] = df_pp[FMs].replace(-9999.99, RFmax)\n",
    "grphv = df_pp.groupby(['Location'])\n",
    "i = 0\n",
    "j = 0\n",
    "w_mode = 'w'\n",
    "for FM in FMs:\n",
    "    df2 = pd.DataFrame()\n",
    "    if i == 1: \n",
    "        w_mode = 'a'\n",
    "        j = 1\n",
    "    header[2] = '$SUBCASE = ' + str(i+1) + ' ' + FM\n",
    "    with open(out_file, w_mode) as output:\n",
    "        writer = csv.writer(output, lineterminator='\\n')\n",
    "        for val in header[j:]:\n",
    "            writer.writerow([val])\n",
    "    \n",
    "    for key, group in grphv:\n",
    "        df1 = grphv.get_group(key)\n",
    "        df2 = df2.append(df1[infos+[FM]].nsmallest(1, FM))\n",
    "    df2 = df2.set_index('Location')\n",
    "    df3 = df2[['ELEMENTS_FRA_1', FM, 'LC_number']]\n",
    "    df3.to_csv(out_file,sep=' ', mode='a', header=False, float_format='%.2f', index=False)\n",
    "    df4 = df2[['ELEMENTS_FRA_2', FM, 'LC_number']]\n",
    "    df4 = df4[df4['ELEMENTS_FRA_2'].notnull()]\n",
    "    df4.to_csv(out_file,sep=' ', mode='a', header=False, float_format='%.2f', index=False)\n",
    "    i = i+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
